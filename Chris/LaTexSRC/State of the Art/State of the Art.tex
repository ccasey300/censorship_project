\chapter{State of the Art}
\section{Introduction}

In order to quantify internet censorship conducted across the globe it is important to understand the different methods used by censors to achieve their aims. Censors engage in a range of steps at various layers of the OSI model in order to either stop the publication of information or make it more difficult for the user to attain. Ultimately, a censors choice of how they detect and interrupt the flow of undesirable information is based on a number of factors such as cost, scalability, and whether the censor wishes to be transparent.

Finding comprehensive and credible resources on censorship mechanisms proved challenging due to the depth of the research area. Requests for Comments (RFCs) proved useful in this regard. These documents highlight internet standards placed by the Internet Engineering Task Force and thus provide the accurate technical specifications needed. RFC 9505 proved invaluable in highlighting the majority of censorship methods used today. It was last updated by the Internet Research Task Force in late 2023 and provides the technical basis for this section of the thesis. The document "describes technical mechanisms employed in network censorship that regimes around the world use for blocking or impairing Internet traffic."\cite{rfc9505} In combination with relevant academic papers, other RFCs like 2818 (HTTPS) \cite{rfc2818} and 8446 (TLS 1.3) \cite{rfc8446} were examined.

\subsection{Overt vs. Covert Censorship }
ICLab, a censorship measurement tool very similar to OONI, released a paper in 2020 describing the need for their contribution \cite{9152784}. In this paper, the author highlights an important distinction between covert and overt censorship: "In overt censorship, the censor sends the user a 'block page' instead of the material that was censored. In covert censorship, the censor causes a network error that could have occurred for other reasons, and thus avoids informing the user that the material was censored.” \cite{9152784} This is a concerning capability as it alludes to the potential for censorship to go unchecked. 


\section{Censorship Techniques and Mechanisms} 

\subsection{Points of Control}
Key control points are nodes in the Internet’s architecture that connect a large user base to the wider network, making them attractive targets for censorship enforcement. RFC 9505 explains points of control in great detail. It states "internet censorship takes place in all parts of the network topology," however, "There are various logical and physical points of control that censors may use for interception mechanism."\cite{rfc9505}. Below are some notable points of control explained.

\textbf{Internet Service Providers (ISPs)}
Entities that accommodate the accessing, using or participating in the internet. Bridging the gap between consumers and the global internet, ISPs are often required to act as "law enforcers and adjudicators." \cite{TOSZA2021105614} Tosza discusses how ISPs and tech giants alike are self-regulating and implicit in internet censorship. Legislation like the Digital Services Act (EU) allows governments to effectively block content deemed harmful at the ISP level.

\textbf{Internet Exchange Points (IXPs)}
A common definition for IXPs is a "network infrastructure with the purpose to facilitate the exchange of Internet traffic between Autonomous Systems (ASes) and operating below layer 3." \cite{DBLP:journals/corr/ChatzisSF13} Put more simply, they are physical locations where different ISPs and networks interconnect to exchange traffic. IEEE describes IXPs as "the facilitator of peering." \cite{6089065}

\textbf{National Gateways}
Refers to the centralised infrastructure through which a country's internet traffic is routed. In a 2009 paper discussing internet infrastructure as it relates to censorship, Karlin and Forrest argue that internet traffic is "increasingly affected by national policies." \cite{DBLP:journals/corr/abs-0903-3218} They go on to illustrate how countries like the UK, Germany and the US are "central to international reachability, and their policies thus have huge potential impact." \cite{DBLP:journals/corr/abs-0903-3218}

\textbf{Institutions}
Businesses, universities and other organisations often have a responsibility to filter the content seen by their users on their network. This is often done to comply with legal obligations, apply ethical standards or to protect network security. This is achieved by a combination of firewalls, keyword-filtering and network level blocking. These techniques are highlighted in Zittrain's 'The Future of the Internet - And How to Stop It,' \cite{zittrain2008future} and will be discussed further below.

\begin{figure} [H]
    \centering
    \includegraphics[width=0.5\linewidth]{State of the Art/KuroseISPs.png}
    \caption{The internet architecture, Jim Kurose Computer Netorking: A Top Down Approach Chapter 1}
    \label{fig:enter-label}
\end{figure}

Governments leverage these nodes in the network topology to restrict user access to undesirable content.  Institutions will typically use a combination of legislative pressure, technological and economic means to snuff out content. ISPs and VPNs face significant and constant pressure from legal arms to expose user data and manipulate the content available to a user. In his research paper from 2003, Zittrain gives a solid overview of points of control. One issue he raises is the violation of the end-to-end principle. Simply, this refers to keeping the middle of the network simple and pushing complexity out towards the edge of the network to hosts. The presence of middleboxes and other devices could be impacting performance of the network. "The technical aspect of the end-to-end argument suggests a warning against blocking data transmissions at any point [other than endpoints]." \cite{Zittrain_Internet_Points_of_Control} 

Although security considerations such as HTTPS and TLS can help protect users from threat actors, points of control are a physical reality to be contended with. As user packets traverse the network they are subject to inspection. In this way, points of control are a key consideration for all internet users. Zittrain concludes his research with a word of warning regarding points of control and their potential for abuse. He highlights the need for "a comprehensive framework where sovereigns’ actions to block material are thoroughly documented and open to challenge." \cite{Zittrain_Internet_Points_of_Control} 

\subsection{Legislative Pressure}
Governments can enforce censorship directly through ISPs, tech companies and social media platforms by creating new legislation or simply mandating content be removed. This is used to de-platform individuals and movements during periods of unrest. This is also done in app stores, shutting down entire platforms that are deemed problematic. More commonly, judiciary process is used in democratic states to block access to illegal sites. Blocking will then be implemented through DNS servers, ISPs, institutions, service providers or otherwise in accordance with court orders. 

VPN providers are subject to the scrutiny of the jurisdiction within which they operate. NordVPN, a very popular VPN provider based in Amserdam has said on record "We will comply with lawful requests as long as they are delivered according to all the laws and regulations." \cite{nordvpnPrivacy2024} This reflects the reality of VPN services as provided by corporations. VPNs in this sense can be described as a double edged sword. In most cases they are very helpful in protecting user anonymity and circumventing censorship. However, if legislative pressure is applied, corporations will have no choice but to comply with the demands of the government. This may be trivial and to be expected by most consumers of VPN services, however, security issues in open source and previously trusted projects like TOR represent a more grave concern. 

\subsection{MITM Attacks}
Kampourakis, Kambourakis, Chatzoglou, and Zaroliagis wrote an academic paper in 2022 arguing the effectiveness of MITM attacks against HTTPS in certain circumstance. They describe a MITM attack as follows. "A man-in-the-middle (MitM) attack enables threat actors to position themselves in a conversation between two parties. It can be used to eavesdrop on, or impersonate, either of the parties and may enable the perpetrator to steal personal information, including login credentials, payment card data and account details."\cite{MITMvHTTPS} A MITM attack simply involves a threat actor, or in this case a censor, placing themselves in the middle of a conversation, potentially at a point of control. Governments have been seen to pressure VPNs into routing traffic through designated MITM servers. Inevitably this allows for selective content manipulation, deep packet inspection and surveillance. MITM attacks are particularly concerning due to their covert and intrusive nature. 

RFC 2818, released in 2000, describes "how to use TLS to secure HTTP connections over the Internet," \cite{rfc2818}known as HTTPS. This was designed to mitigate the effects of MITM attacks. Recent research suggests deployments of HTTPS in most browsers is insecure, at least in certain circumstance. Kampourakis and his colleagues went on to say "some insidious variants of MitM against HTTPS remain quite realistic across all popular Internet browser types irrespective of the underlying platform." \cite{MITMvHTTPS} 
They mention how "both of the attack variations were successful against all the browser types and versions..." except the latest versions of Firefox that they tested.

\section{Network-Level Filtering}
The following section is based primarily on information from the source \textit{RFC 9505 A Survey of Worldwide Censorship Techniques} \cite{rfc9505}. Any other information sourced from elsewhere is identified as such.

\subsection{IP Blocking}
Originally implemented to stop email spam, Internet Protocol (IP) blocking is one of the most straightforward censorship techniques. Each device connected to the internet is assigned a unique numeric label called an IP Address, which serves as an identifier that allows data to travel across the internet to the correct destination. RFC 791 describes the function of the Internet Protocol, "to move datagrams through an interconnected set of networks." \cite{rfc791}

When a government or ISP wants to censor a specific website it can be implemented in either incoming or outgoing traffic. ISP controlled firewalls can be configured so that any outgoing or incoming requests to a selected IP address are dropped. ISPs can also adjust routing tables in their network to remove an IP address, making it unreachable for the user. In a 2009 report, Callanan and co. describe how "the server that contains the website could be blocked at the level of its IP address, preventing anyone using the filter from accessing that address." \cite{inthemis2025internet} IP blocking can either be implemented at a centralized level or at an ISP level. In Ireland, IP blocking is done at an ISP level to block certain illegal websites. The primary motivation for the Irish government in doing this is to crack down on piracy. A prime example discussed previously is the blocking of the Pirate Bay. \cite{piratebay_block2013}

\begin{figure} [H]
    \centering
    \includegraphics[width=1\linewidth]{DNSimg.png}
    \caption{DNS Request resolution. https://medium.com/@kmwende419/dns-request-3baa4dd588f1}
    \label{fig:enter-label}
\end{figure}


\subsection{DNS Interference}
DNS interference refers to the altering of responses from the DNS to block or filter access to certain content. This is usually done by either blocking the response, replying with an error message, or responding with an incorrect address. 
\textit{DNS Mangling} is a network-level technique of on-path interception where an incorrect IP address is returned in response to a DNS query to a censored destination. 
\textit{DNS Cache Poisoning \& Lying} is an off-path technique in which a censor intercepts and replaces the legitimate response from an authoritative DNS name server with a spoofed IP address. Instead of allowing the real IP address of a site to reach the user, the censor replies faster than the real server, and that spoofed IP gets cached (perhaps by numerous recursive resolvers). Subsequent requests will then be redirected to an incorrect IP, normally leading to a warning page or a meaningless domain. DNS lying on the other hand involves the censor mandating that the DNS server provide a particular response. Of all of the methods to tamper with DNS resolution this is the most aggressive. \cite{rfc9505}.

The above DNS interference methods require the censor to traverse a controlled DNS hierarchy for this mechanism to be effective. This mechanism can be circumvented by using a different publicly known DNS resolver that is not controlled by the censor. This mechanism can also lead to unintentional blocking in area's not controlled by the censor. For example, sometimes a user outside of the censor's region will be directed through DNS servers controlled by the censor, causing the request to fail. 

\subsection{Network Blackouts}
A very straightforward, holistic, and blunt form of censorship is network blackouts. This method involves a large governing body of an area or region completely shutting off Internet access for all content. This method is becoming more and more common across areas in the Middle East and Asia. According to a report from \textit{Access Now}, there were a total of 296 different internet shutdowns across 54 countries. \cite{accessnowBlackoutReport2023} This is a 35\% increase from the previous high in 2022 \cite{internetblackouts}. This form of censorship is very extreme and is often implemented in times of conflict, protest and democratic instability. 


\section{Keyword Filtering \& Deep Packet Inspection}
So far, methods of internet censorship have revolved around blocking a publishers address. However censors can examine the contents within packets to make decisions regarding their accessibility. This refers to the concept of application layer filtering; monitoring a communication channel and detecting offensive keywords. This is seen in more cultivated censorship models that strive to censor topic 'x'. 

\textit{Keyword Filtering} This approach involves scanning the contents of web requests for specific sensitive words or phrases. Upon encountering a request that contains a blacklisted keyword, the censor can disrupt the communication by, for example, sending TCP reset packets to both sides. This is a simple approach that is easily implemented. Pattil, in a 2014 paper, described this process saying "any packet that is passed across the network is scanned against a list of sensitive keywords and if present it forces the connection to terminate." \cite{uta-cse-1227} Circumventing keyword filtering is not particularly difficult. Coy publishers will employ deliberate misspelling or use of synonyms in place of sensitive keywords. 

A notorious example of keyword filtering in the real world is China's censorship of the 1989 Tiananmen Square protests. The Chinese government has been dedicated to removing this from the memory of its citizens, particularly the younger generation. \cite{nsarchive2001tiananmen} Louisa Lim, while researching this topic in 2014, polled Chinese students at four Beijing campuses and found that "out of 100 students, only 15 could identify the [Tank Man] picture." \cite{lim2014amnesia} In December of last year it surfaced that Tokyo University had embedded a keyword relating to the incident into one of its online applications. In an apparent attempt to prevent the page from loading in mainland China and stop Chinese students from applying, the university weaponised the Great Chinese Firewall. This is a prime example of the limitations of keyword filtering. \cite{unseenjapan2023tiananmen}

\textit{Deep Packet Inspection} DPI involves looking into payloads and data within packets, beyond its header. It is a sophisticated technique usually performed as part of a firewall defense and involves making real time decisions about the nature of each packet. DPI functions at the application level and can be used to identify both the sender and recipient of the packet by examining its payload. Compared to regular packet inspection which is only concerned with basic header information, it is considerably more costly. 

Deep packet inspection is used in specific cases where a higher level of audit is required. This includes packets carrying malware, content that has been blocked and intrusion efforts. DPI is usually performed by network middle boxes, devices that lie between end points. One of the these middle boxes is BlindBox, a system that accommodates DPI while preserving privacy and encryption. The creators of this system highlight the potential risks to user privacy with other black boxes. "To enable middlebox processing, some currently deployed middlebox systems support HTTPS in
an insecure way: they mount a man-in-the-middle attack on SSL and decrypt the traffic at the middlebox." \cite{sherry2015blindbox}

Though its deployment is limited, DPI represents a significant risk to user privacy. Not all middle box providers offer the protections and guarantees that BlindBox offer. Forecasts for the market show a troubling trend, with no guarantees of user privacy. "Global deep packet inspection (DPI) market size was anticipated to be worth USD 10.63 billion in 2024 and is expected to reach USD 79.26 billion by 2033 at a CAGR of 25\% during the forecast period." \cite{DPIMarketInfo}

